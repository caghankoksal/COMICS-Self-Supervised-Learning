{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint0020.pth',\n",
       " 'checkpoint.pth',\n",
       " 'checkpoint0000.pth',\n",
       " 'dino_comics_swin_ss.pth',\n",
       " 'log.txt',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"results_bs64_v100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('/scratch/users/ckoksal20/COMICS_Self_Supervised_Learning/DINO/dino',\n",
    "                    \"results_bs64_v100\",\n",
    "                    'dino_comics_swin_ss.pth')\n",
    "weights = torch.load(path)\n",
    "mdl = OrderedDict()\n",
    "for k in weights[\"teacher\"]:\n",
    "    #print(k.replace('backbone.','').replace('stages','layers').replace('projection','proj'), \"  -----> \", weights[\"teacher\"][k].shape)\n",
    "    print(\"K : \", k, \"Value : \", weights[\"teacher\"][k].shape)\n",
    "    #cur_name = k.replace('backbone.','').replace('stages','layers').replace('projection','proj').replace('w_msa.','')\n",
    "    #mdl[cur_name] = weights[\"teacher\"][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K :  backbone.patch_embed.projection.weight Value :  torch.Size([96, 3, 4, 4])\n",
      "K :  backbone.patch_embed.projection.bias Value :  torch.Size([96])\n",
      "K :  backbone.patch_embed.norm.weight Value :  torch.Size([96])\n",
      "K :  backbone.patch_embed.norm.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.0.norm1.weight Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.0.norm1.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 3])\n",
      "K :  backbone.stages.0.blocks.0.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.0.blocks.0.attn.w_msa.qkv.weight Value :  torch.Size([288, 96])\n",
      "K :  backbone.stages.0.blocks.0.attn.w_msa.qkv.bias Value :  torch.Size([288])\n",
      "K :  backbone.stages.0.blocks.0.attn.w_msa.proj.weight Value :  torch.Size([96, 96])\n",
      "K :  backbone.stages.0.blocks.0.attn.w_msa.proj.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.0.norm2.weight Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.0.norm2.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.0.ffn.layers.0.0.weight Value :  torch.Size([384, 96])\n",
      "K :  backbone.stages.0.blocks.0.ffn.layers.0.0.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.0.blocks.0.ffn.layers.1.weight Value :  torch.Size([96, 384])\n",
      "K :  backbone.stages.0.blocks.0.ffn.layers.1.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.1.norm1.weight Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.1.norm1.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 3])\n",
      "K :  backbone.stages.0.blocks.1.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.0.blocks.1.attn.w_msa.qkv.weight Value :  torch.Size([288, 96])\n",
      "K :  backbone.stages.0.blocks.1.attn.w_msa.qkv.bias Value :  torch.Size([288])\n",
      "K :  backbone.stages.0.blocks.1.attn.w_msa.proj.weight Value :  torch.Size([96, 96])\n",
      "K :  backbone.stages.0.blocks.1.attn.w_msa.proj.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.1.norm2.weight Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.1.norm2.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.1.ffn.layers.0.0.weight Value :  torch.Size([384, 96])\n",
      "K :  backbone.stages.0.blocks.1.ffn.layers.0.0.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.0.blocks.1.ffn.layers.1.weight Value :  torch.Size([96, 384])\n",
      "K :  backbone.stages.0.blocks.1.ffn.layers.1.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.downsample.norm.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.0.downsample.norm.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.0.downsample.reduction.weight Value :  torch.Size([192, 384])\n",
      "K :  backbone.stages.1.blocks.0.norm1.weight Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.0.norm1.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 6])\n",
      "K :  backbone.stages.1.blocks.0.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.1.blocks.0.attn.w_msa.qkv.weight Value :  torch.Size([576, 192])\n",
      "K :  backbone.stages.1.blocks.0.attn.w_msa.qkv.bias Value :  torch.Size([576])\n",
      "K :  backbone.stages.1.blocks.0.attn.w_msa.proj.weight Value :  torch.Size([192, 192])\n",
      "K :  backbone.stages.1.blocks.0.attn.w_msa.proj.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.0.norm2.weight Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.0.norm2.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.0.ffn.layers.0.0.weight Value :  torch.Size([768, 192])\n",
      "K :  backbone.stages.1.blocks.0.ffn.layers.0.0.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.1.blocks.0.ffn.layers.1.weight Value :  torch.Size([192, 768])\n",
      "K :  backbone.stages.1.blocks.0.ffn.layers.1.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.1.norm1.weight Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.1.norm1.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 6])\n",
      "K :  backbone.stages.1.blocks.1.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.1.blocks.1.attn.w_msa.qkv.weight Value :  torch.Size([576, 192])\n",
      "K :  backbone.stages.1.blocks.1.attn.w_msa.qkv.bias Value :  torch.Size([576])\n",
      "K :  backbone.stages.1.blocks.1.attn.w_msa.proj.weight Value :  torch.Size([192, 192])\n",
      "K :  backbone.stages.1.blocks.1.attn.w_msa.proj.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.1.norm2.weight Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.1.norm2.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.1.ffn.layers.0.0.weight Value :  torch.Size([768, 192])\n",
      "K :  backbone.stages.1.blocks.1.ffn.layers.0.0.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.1.blocks.1.ffn.layers.1.weight Value :  torch.Size([192, 768])\n",
      "K :  backbone.stages.1.blocks.1.ffn.layers.1.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.downsample.norm.weight Value :  torch.Size([768])\n",
      "K :  backbone.stages.1.downsample.norm.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.1.downsample.reduction.weight Value :  torch.Size([384, 768])\n",
      "K :  backbone.stages.2.blocks.0.norm1.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.0.norm1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 12])\n",
      "K :  backbone.stages.2.blocks.0.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.2.blocks.0.attn.w_msa.qkv.weight Value :  torch.Size([1152, 384])\n",
      "K :  backbone.stages.2.blocks.0.attn.w_msa.qkv.bias Value :  torch.Size([1152])\n",
      "K :  backbone.stages.2.blocks.0.attn.w_msa.proj.weight Value :  torch.Size([384, 384])\n",
      "K :  backbone.stages.2.blocks.0.attn.w_msa.proj.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.0.norm2.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.0.norm2.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.0.ffn.layers.0.0.weight Value :  torch.Size([1536, 384])\n",
      "K :  backbone.stages.2.blocks.0.ffn.layers.0.0.bias Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.blocks.0.ffn.layers.1.weight Value :  torch.Size([384, 1536])\n",
      "K :  backbone.stages.2.blocks.0.ffn.layers.1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.1.norm1.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.1.norm1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 12])\n",
      "K :  backbone.stages.2.blocks.1.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.2.blocks.1.attn.w_msa.qkv.weight Value :  torch.Size([1152, 384])\n",
      "K :  backbone.stages.2.blocks.1.attn.w_msa.qkv.bias Value :  torch.Size([1152])\n",
      "K :  backbone.stages.2.blocks.1.attn.w_msa.proj.weight Value :  torch.Size([384, 384])\n",
      "K :  backbone.stages.2.blocks.1.attn.w_msa.proj.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.1.norm2.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.1.norm2.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.1.ffn.layers.0.0.weight Value :  torch.Size([1536, 384])\n",
      "K :  backbone.stages.2.blocks.1.ffn.layers.0.0.bias Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.blocks.1.ffn.layers.1.weight Value :  torch.Size([384, 1536])\n",
      "K :  backbone.stages.2.blocks.1.ffn.layers.1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.2.norm1.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.2.norm1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 12])\n",
      "K :  backbone.stages.2.blocks.2.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.2.blocks.2.attn.w_msa.qkv.weight Value :  torch.Size([1152, 384])\n",
      "K :  backbone.stages.2.blocks.2.attn.w_msa.qkv.bias Value :  torch.Size([1152])\n",
      "K :  backbone.stages.2.blocks.2.attn.w_msa.proj.weight Value :  torch.Size([384, 384])\n",
      "K :  backbone.stages.2.blocks.2.attn.w_msa.proj.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.2.norm2.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.2.norm2.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.2.ffn.layers.0.0.weight Value :  torch.Size([1536, 384])\n",
      "K :  backbone.stages.2.blocks.2.ffn.layers.0.0.bias Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.blocks.2.ffn.layers.1.weight Value :  torch.Size([384, 1536])\n",
      "K :  backbone.stages.2.blocks.2.ffn.layers.1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.3.norm1.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.3.norm1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 12])\n",
      "K :  backbone.stages.2.blocks.3.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.2.blocks.3.attn.w_msa.qkv.weight Value :  torch.Size([1152, 384])\n",
      "K :  backbone.stages.2.blocks.3.attn.w_msa.qkv.bias Value :  torch.Size([1152])\n",
      "K :  backbone.stages.2.blocks.3.attn.w_msa.proj.weight Value :  torch.Size([384, 384])\n",
      "K :  backbone.stages.2.blocks.3.attn.w_msa.proj.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.3.norm2.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.3.norm2.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.3.ffn.layers.0.0.weight Value :  torch.Size([1536, 384])\n",
      "K :  backbone.stages.2.blocks.3.ffn.layers.0.0.bias Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.blocks.3.ffn.layers.1.weight Value :  torch.Size([384, 1536])\n",
      "K :  backbone.stages.2.blocks.3.ffn.layers.1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.4.norm1.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.4.norm1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 12])\n",
      "K :  backbone.stages.2.blocks.4.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.2.blocks.4.attn.w_msa.qkv.weight Value :  torch.Size([1152, 384])\n",
      "K :  backbone.stages.2.blocks.4.attn.w_msa.qkv.bias Value :  torch.Size([1152])\n",
      "K :  backbone.stages.2.blocks.4.attn.w_msa.proj.weight Value :  torch.Size([384, 384])\n",
      "K :  backbone.stages.2.blocks.4.attn.w_msa.proj.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.4.norm2.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.4.norm2.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.4.ffn.layers.0.0.weight Value :  torch.Size([1536, 384])\n",
      "K :  backbone.stages.2.blocks.4.ffn.layers.0.0.bias Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.blocks.4.ffn.layers.1.weight Value :  torch.Size([384, 1536])\n",
      "K :  backbone.stages.2.blocks.4.ffn.layers.1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.5.norm1.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.5.norm1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 12])\n",
      "K :  backbone.stages.2.blocks.5.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.2.blocks.5.attn.w_msa.qkv.weight Value :  torch.Size([1152, 384])\n",
      "K :  backbone.stages.2.blocks.5.attn.w_msa.qkv.bias Value :  torch.Size([1152])\n",
      "K :  backbone.stages.2.blocks.5.attn.w_msa.proj.weight Value :  torch.Size([384, 384])\n",
      "K :  backbone.stages.2.blocks.5.attn.w_msa.proj.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.5.norm2.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.5.norm2.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.5.ffn.layers.0.0.weight Value :  torch.Size([1536, 384])\n",
      "K :  backbone.stages.2.blocks.5.ffn.layers.0.0.bias Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.blocks.5.ffn.layers.1.weight Value :  torch.Size([384, 1536])\n",
      "K :  backbone.stages.2.blocks.5.ffn.layers.1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.downsample.norm.weight Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.downsample.norm.bias Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.downsample.reduction.weight Value :  torch.Size([768, 1536])\n",
      "K :  backbone.stages.3.blocks.0.norm1.weight Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.0.norm1.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 24])\n",
      "K :  backbone.stages.3.blocks.0.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.3.blocks.0.attn.w_msa.qkv.weight Value :  torch.Size([2304, 768])\n",
      "K :  backbone.stages.3.blocks.0.attn.w_msa.qkv.bias Value :  torch.Size([2304])\n",
      "K :  backbone.stages.3.blocks.0.attn.w_msa.proj.weight Value :  torch.Size([768, 768])\n",
      "K :  backbone.stages.3.blocks.0.attn.w_msa.proj.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.0.norm2.weight Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.0.norm2.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.0.ffn.layers.0.0.weight Value :  torch.Size([3072, 768])\n",
      "K :  backbone.stages.3.blocks.0.ffn.layers.0.0.bias Value :  torch.Size([3072])\n",
      "K :  backbone.stages.3.blocks.0.ffn.layers.1.weight Value :  torch.Size([768, 3072])\n",
      "K :  backbone.stages.3.blocks.0.ffn.layers.1.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.1.norm1.weight Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.1.norm1.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 24])\n",
      "K :  backbone.stages.3.blocks.1.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.3.blocks.1.attn.w_msa.qkv.weight Value :  torch.Size([2304, 768])\n",
      "K :  backbone.stages.3.blocks.1.attn.w_msa.qkv.bias Value :  torch.Size([2304])\n",
      "K :  backbone.stages.3.blocks.1.attn.w_msa.proj.weight Value :  torch.Size([768, 768])\n",
      "K :  backbone.stages.3.blocks.1.attn.w_msa.proj.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.1.norm2.weight Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.1.norm2.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.1.ffn.layers.0.0.weight Value :  torch.Size([3072, 768])\n",
      "K :  backbone.stages.3.blocks.1.ffn.layers.0.0.bias Value :  torch.Size([3072])\n",
      "K :  backbone.stages.3.blocks.1.ffn.layers.1.weight Value :  torch.Size([768, 3072])\n",
      "K :  backbone.stages.3.blocks.1.ffn.layers.1.bias Value :  torch.Size([768])\n",
      "K :  backbone.norm0.weight Value :  torch.Size([96])\n",
      "K :  backbone.norm0.bias Value :  torch.Size([96])\n",
      "K :  backbone.norm1.weight Value :  torch.Size([192])\n",
      "K :  backbone.norm1.bias Value :  torch.Size([192])\n",
      "K :  backbone.norm2.weight Value :  torch.Size([384])\n",
      "K :  backbone.norm2.bias Value :  torch.Size([384])\n",
      "K :  backbone.norm3.weight Value :  torch.Size([768])\n",
      "K :  backbone.norm3.bias Value :  torch.Size([768])\n",
      "K :  backbone.ln.weight Value :  torch.Size([768])\n",
      "K :  backbone.ln.bias Value :  torch.Size([768])\n",
      "K :  head.mlp.0.weight Value :  torch.Size([2048, 768])\n",
      "K :  head.mlp.0.bias Value :  torch.Size([2048])\n",
      "K :  head.mlp.2.weight Value :  torch.Size([2048, 2048])\n",
      "K :  head.mlp.2.bias Value :  torch.Size([2048])\n",
      "K :  head.mlp.4.weight Value :  torch.Size([256, 2048])\n",
      "K :  head.mlp.4.bias Value :  torch.Size([256])\n",
      "K :  head.last_layer.weight_g Value :  torch.Size([65536, 1])\n",
      "K :  head.last_layer.weight_v Value :  torch.Size([65536, 256])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dict()\n",
    "out[\"model\"] = mdl\n",
    "torch.save(out, \"dino_swins_epoch19.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swin_tiny = torch.load('swin_tiny_patch4_window7_224.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swin_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in swin_tiny[\"model\"].items():\n",
    "    print(\" K : \",k, \" V: \",v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K :  neck.lateral_convs.0.conv.weight    V:  torch.Size([256, 96, 1, 1])\n",
      " K :  neck.lateral_convs.0.conv.bias    V:  torch.Size([256])\n",
      " K :  neck.lateral_convs.1.conv.weight    V:  torch.Size([256, 192, 1, 1])\n",
      " K :  neck.lateral_convs.1.conv.bias    V:  torch.Size([256])\n",
      " K :  neck.lateral_convs.2.conv.weight    V:  torch.Size([256, 384, 1, 1])\n",
      " K :  neck.lateral_convs.2.conv.bias    V:  torch.Size([256])\n",
      " K :  neck.lateral_convs.3.conv.weight    V:  torch.Size([256, 768, 1, 1])\n",
      " K :  neck.lateral_convs.3.conv.bias    V:  torch.Size([256])\n",
      " K :  neck.fpn_convs.0.conv.weight    V:  torch.Size([256, 256, 3, 3])\n",
      " K :  neck.fpn_convs.0.conv.bias    V:  torch.Size([256])\n",
      " K :  neck.fpn_convs.1.conv.weight    V:  torch.Size([256, 256, 3, 3])\n",
      " K :  neck.fpn_convs.1.conv.bias    V:  torch.Size([256])\n",
      " K :  neck.fpn_convs.2.conv.weight    V:  torch.Size([256, 256, 3, 3])\n",
      " K :  neck.fpn_convs.2.conv.bias    V:  torch.Size([256])\n",
      " K :  neck.fpn_convs.3.conv.weight    V:  torch.Size([256, 256, 3, 3])\n",
      " K :  neck.fpn_convs.3.conv.bias    V:  torch.Size([256])\n",
      " K :  rpn_head.rpn_conv.weight    V:  torch.Size([256, 256, 3, 3])\n",
      " K :  rpn_head.rpn_conv.bias    V:  torch.Size([256])\n",
      " K :  rpn_head.rpn_cls.weight    V:  torch.Size([3, 256, 1, 1])\n",
      " K :  rpn_head.rpn_cls.bias    V:  torch.Size([3])\n",
      " K :  rpn_head.rpn_reg.weight    V:  torch.Size([12, 256, 1, 1])\n",
      " K :  rpn_head.rpn_reg.bias    V:  torch.Size([12])\n",
      " K :  roi_head.bbox_head.fc_cls.weight    V:  torch.Size([81, 1024])\n",
      " K :  roi_head.bbox_head.fc_cls.bias    V:  torch.Size([81])\n",
      " K :  roi_head.bbox_head.fc_reg.weight    V:  torch.Size([320, 1024])\n",
      " K :  roi_head.bbox_head.fc_reg.bias    V:  torch.Size([320])\n",
      " K :  roi_head.bbox_head.shared_fcs.0.weight    V:  torch.Size([1024, 12544])\n",
      " K :  roi_head.bbox_head.shared_fcs.0.bias    V:  torch.Size([1024])\n",
      " K :  roi_head.bbox_head.shared_fcs.1.weight    V:  torch.Size([1024, 1024])\n",
      " K :  roi_head.bbox_head.shared_fcs.1.bias    V:  torch.Size([1024])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K :  backbone.patch_embed.projection.weight Value :  torch.Size([96, 3, 4, 4])\n",
      "K :  backbone.patch_embed.projection.bias Value :  torch.Size([96])\n",
      "K :  backbone.patch_embed.norm.weight Value :  torch.Size([96])\n",
      "K :  backbone.patch_embed.norm.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.0.norm1.weight Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.0.norm1.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 3])\n",
      "K :  backbone.stages.0.blocks.0.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.0.blocks.0.attn.w_msa.qkv.weight Value :  torch.Size([288, 96])\n",
      "K :  backbone.stages.0.blocks.0.attn.w_msa.qkv.bias Value :  torch.Size([288])\n",
      "K :  backbone.stages.0.blocks.0.attn.w_msa.proj.weight Value :  torch.Size([96, 96])\n",
      "K :  backbone.stages.0.blocks.0.attn.w_msa.proj.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.0.norm2.weight Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.0.norm2.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.0.ffn.layers.0.0.weight Value :  torch.Size([384, 96])\n",
      "K :  backbone.stages.0.blocks.0.ffn.layers.0.0.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.0.blocks.0.ffn.layers.1.weight Value :  torch.Size([96, 384])\n",
      "K :  backbone.stages.0.blocks.0.ffn.layers.1.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.1.norm1.weight Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.1.norm1.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 3])\n",
      "K :  backbone.stages.0.blocks.1.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.0.blocks.1.attn.w_msa.qkv.weight Value :  torch.Size([288, 96])\n",
      "K :  backbone.stages.0.blocks.1.attn.w_msa.qkv.bias Value :  torch.Size([288])\n",
      "K :  backbone.stages.0.blocks.1.attn.w_msa.proj.weight Value :  torch.Size([96, 96])\n",
      "K :  backbone.stages.0.blocks.1.attn.w_msa.proj.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.1.norm2.weight Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.1.norm2.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.blocks.1.ffn.layers.0.0.weight Value :  torch.Size([384, 96])\n",
      "K :  backbone.stages.0.blocks.1.ffn.layers.0.0.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.0.blocks.1.ffn.layers.1.weight Value :  torch.Size([96, 384])\n",
      "K :  backbone.stages.0.blocks.1.ffn.layers.1.bias Value :  torch.Size([96])\n",
      "K :  backbone.stages.0.downsample.norm.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.0.downsample.norm.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.0.downsample.reduction.weight Value :  torch.Size([192, 384])\n",
      "K :  backbone.stages.1.blocks.0.norm1.weight Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.0.norm1.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 6])\n",
      "K :  backbone.stages.1.blocks.0.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.1.blocks.0.attn.w_msa.qkv.weight Value :  torch.Size([576, 192])\n",
      "K :  backbone.stages.1.blocks.0.attn.w_msa.qkv.bias Value :  torch.Size([576])\n",
      "K :  backbone.stages.1.blocks.0.attn.w_msa.proj.weight Value :  torch.Size([192, 192])\n",
      "K :  backbone.stages.1.blocks.0.attn.w_msa.proj.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.0.norm2.weight Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.0.norm2.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.0.ffn.layers.0.0.weight Value :  torch.Size([768, 192])\n",
      "K :  backbone.stages.1.blocks.0.ffn.layers.0.0.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.1.blocks.0.ffn.layers.1.weight Value :  torch.Size([192, 768])\n",
      "K :  backbone.stages.1.blocks.0.ffn.layers.1.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.1.norm1.weight Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.1.norm1.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 6])\n",
      "K :  backbone.stages.1.blocks.1.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.1.blocks.1.attn.w_msa.qkv.weight Value :  torch.Size([576, 192])\n",
      "K :  backbone.stages.1.blocks.1.attn.w_msa.qkv.bias Value :  torch.Size([576])\n",
      "K :  backbone.stages.1.blocks.1.attn.w_msa.proj.weight Value :  torch.Size([192, 192])\n",
      "K :  backbone.stages.1.blocks.1.attn.w_msa.proj.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.1.norm2.weight Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.1.norm2.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.blocks.1.ffn.layers.0.0.weight Value :  torch.Size([768, 192])\n",
      "K :  backbone.stages.1.blocks.1.ffn.layers.0.0.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.1.blocks.1.ffn.layers.1.weight Value :  torch.Size([192, 768])\n",
      "K :  backbone.stages.1.blocks.1.ffn.layers.1.bias Value :  torch.Size([192])\n",
      "K :  backbone.stages.1.downsample.norm.weight Value :  torch.Size([768])\n",
      "K :  backbone.stages.1.downsample.norm.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.1.downsample.reduction.weight Value :  torch.Size([384, 768])\n",
      "K :  backbone.stages.2.blocks.0.norm1.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.0.norm1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 12])\n",
      "K :  backbone.stages.2.blocks.0.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.2.blocks.0.attn.w_msa.qkv.weight Value :  torch.Size([1152, 384])\n",
      "K :  backbone.stages.2.blocks.0.attn.w_msa.qkv.bias Value :  torch.Size([1152])\n",
      "K :  backbone.stages.2.blocks.0.attn.w_msa.proj.weight Value :  torch.Size([384, 384])\n",
      "K :  backbone.stages.2.blocks.0.attn.w_msa.proj.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.0.norm2.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.0.norm2.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.0.ffn.layers.0.0.weight Value :  torch.Size([1536, 384])\n",
      "K :  backbone.stages.2.blocks.0.ffn.layers.0.0.bias Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.blocks.0.ffn.layers.1.weight Value :  torch.Size([384, 1536])\n",
      "K :  backbone.stages.2.blocks.0.ffn.layers.1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.1.norm1.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.1.norm1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 12])\n",
      "K :  backbone.stages.2.blocks.1.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.2.blocks.1.attn.w_msa.qkv.weight Value :  torch.Size([1152, 384])\n",
      "K :  backbone.stages.2.blocks.1.attn.w_msa.qkv.bias Value :  torch.Size([1152])\n",
      "K :  backbone.stages.2.blocks.1.attn.w_msa.proj.weight Value :  torch.Size([384, 384])\n",
      "K :  backbone.stages.2.blocks.1.attn.w_msa.proj.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.1.norm2.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.1.norm2.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.1.ffn.layers.0.0.weight Value :  torch.Size([1536, 384])\n",
      "K :  backbone.stages.2.blocks.1.ffn.layers.0.0.bias Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.blocks.1.ffn.layers.1.weight Value :  torch.Size([384, 1536])\n",
      "K :  backbone.stages.2.blocks.1.ffn.layers.1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.2.norm1.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.2.norm1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 12])\n",
      "K :  backbone.stages.2.blocks.2.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.2.blocks.2.attn.w_msa.qkv.weight Value :  torch.Size([1152, 384])\n",
      "K :  backbone.stages.2.blocks.2.attn.w_msa.qkv.bias Value :  torch.Size([1152])\n",
      "K :  backbone.stages.2.blocks.2.attn.w_msa.proj.weight Value :  torch.Size([384, 384])\n",
      "K :  backbone.stages.2.blocks.2.attn.w_msa.proj.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.2.norm2.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.2.norm2.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.2.ffn.layers.0.0.weight Value :  torch.Size([1536, 384])\n",
      "K :  backbone.stages.2.blocks.2.ffn.layers.0.0.bias Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.blocks.2.ffn.layers.1.weight Value :  torch.Size([384, 1536])\n",
      "K :  backbone.stages.2.blocks.2.ffn.layers.1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.3.norm1.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.3.norm1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 12])\n",
      "K :  backbone.stages.2.blocks.3.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.2.blocks.3.attn.w_msa.qkv.weight Value :  torch.Size([1152, 384])\n",
      "K :  backbone.stages.2.blocks.3.attn.w_msa.qkv.bias Value :  torch.Size([1152])\n",
      "K :  backbone.stages.2.blocks.3.attn.w_msa.proj.weight Value :  torch.Size([384, 384])\n",
      "K :  backbone.stages.2.blocks.3.attn.w_msa.proj.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.3.norm2.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.3.norm2.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.3.ffn.layers.0.0.weight Value :  torch.Size([1536, 384])\n",
      "K :  backbone.stages.2.blocks.3.ffn.layers.0.0.bias Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.blocks.3.ffn.layers.1.weight Value :  torch.Size([384, 1536])\n",
      "K :  backbone.stages.2.blocks.3.ffn.layers.1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.4.norm1.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.4.norm1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 12])\n",
      "K :  backbone.stages.2.blocks.4.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.2.blocks.4.attn.w_msa.qkv.weight Value :  torch.Size([1152, 384])\n",
      "K :  backbone.stages.2.blocks.4.attn.w_msa.qkv.bias Value :  torch.Size([1152])\n",
      "K :  backbone.stages.2.blocks.4.attn.w_msa.proj.weight Value :  torch.Size([384, 384])\n",
      "K :  backbone.stages.2.blocks.4.attn.w_msa.proj.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.4.norm2.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.4.norm2.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.4.ffn.layers.0.0.weight Value :  torch.Size([1536, 384])\n",
      "K :  backbone.stages.2.blocks.4.ffn.layers.0.0.bias Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.blocks.4.ffn.layers.1.weight Value :  torch.Size([384, 1536])\n",
      "K :  backbone.stages.2.blocks.4.ffn.layers.1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.5.norm1.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.5.norm1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 12])\n",
      "K :  backbone.stages.2.blocks.5.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.2.blocks.5.attn.w_msa.qkv.weight Value :  torch.Size([1152, 384])\n",
      "K :  backbone.stages.2.blocks.5.attn.w_msa.qkv.bias Value :  torch.Size([1152])\n",
      "K :  backbone.stages.2.blocks.5.attn.w_msa.proj.weight Value :  torch.Size([384, 384])\n",
      "K :  backbone.stages.2.blocks.5.attn.w_msa.proj.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.5.norm2.weight Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.5.norm2.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.blocks.5.ffn.layers.0.0.weight Value :  torch.Size([1536, 384])\n",
      "K :  backbone.stages.2.blocks.5.ffn.layers.0.0.bias Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.blocks.5.ffn.layers.1.weight Value :  torch.Size([384, 1536])\n",
      "K :  backbone.stages.2.blocks.5.ffn.layers.1.bias Value :  torch.Size([384])\n",
      "K :  backbone.stages.2.downsample.norm.weight Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.downsample.norm.bias Value :  torch.Size([1536])\n",
      "K :  backbone.stages.2.downsample.reduction.weight Value :  torch.Size([768, 1536])\n",
      "K :  backbone.stages.3.blocks.0.norm1.weight Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.0.norm1.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 24])\n",
      "K :  backbone.stages.3.blocks.0.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.3.blocks.0.attn.w_msa.qkv.weight Value :  torch.Size([2304, 768])\n",
      "K :  backbone.stages.3.blocks.0.attn.w_msa.qkv.bias Value :  torch.Size([2304])\n",
      "K :  backbone.stages.3.blocks.0.attn.w_msa.proj.weight Value :  torch.Size([768, 768])\n",
      "K :  backbone.stages.3.blocks.0.attn.w_msa.proj.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.0.norm2.weight Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.0.norm2.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.0.ffn.layers.0.0.weight Value :  torch.Size([3072, 768])\n",
      "K :  backbone.stages.3.blocks.0.ffn.layers.0.0.bias Value :  torch.Size([3072])\n",
      "K :  backbone.stages.3.blocks.0.ffn.layers.1.weight Value :  torch.Size([768, 3072])\n",
      "K :  backbone.stages.3.blocks.0.ffn.layers.1.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.1.norm1.weight Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.1.norm1.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table Value :  torch.Size([169, 24])\n",
      "K :  backbone.stages.3.blocks.1.attn.w_msa.relative_position_index Value :  torch.Size([49, 49])\n",
      "K :  backbone.stages.3.blocks.1.attn.w_msa.qkv.weight Value :  torch.Size([2304, 768])\n",
      "K :  backbone.stages.3.blocks.1.attn.w_msa.qkv.bias Value :  torch.Size([2304])\n",
      "K :  backbone.stages.3.blocks.1.attn.w_msa.proj.weight Value :  torch.Size([768, 768])\n",
      "K :  backbone.stages.3.blocks.1.attn.w_msa.proj.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.1.norm2.weight Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.1.norm2.bias Value :  torch.Size([768])\n",
      "K :  backbone.stages.3.blocks.1.ffn.layers.0.0.weight Value :  torch.Size([3072, 768])\n",
      "K :  backbone.stages.3.blocks.1.ffn.layers.0.0.bias Value :  torch.Size([3072])\n",
      "K :  backbone.stages.3.blocks.1.ffn.layers.1.weight Value :  torch.Size([768, 3072])\n",
      "K :  backbone.stages.3.blocks.1.ffn.layers.1.bias Value :  torch.Size([768])\n",
      "K :  backbone.norm0.weight Value :  torch.Size([96])\n",
      "K :  backbone.norm0.bias Value :  torch.Size([96])\n",
      "K :  backbone.norm1.weight Value :  torch.Size([192])\n",
      "K :  backbone.norm1.bias Value :  torch.Size([192])\n",
      "K :  backbone.norm2.weight Value :  torch.Size([384])\n",
      "K :  backbone.norm2.bias Value :  torch.Size([384])\n",
      "K :  backbone.norm3.weight Value :  torch.Size([768])\n",
      "K :  backbone.norm3.bias Value :  torch.Size([768])\n",
      "K :  backbone.ln.weight Value :  torch.Size([768])\n",
      "K :  backbone.ln.bias Value :  torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "model_backbone_DINO_SWIN_FPN_HEAD_MASKRCNN = OrderedDict()\n",
    "\n",
    "# DINO PRETRAINED BACKBONE WEIGHTS\n",
    "path = os.path.join('/scratch/users/ckoksal20/COMICS_Self_Supervised_Learning/DINO/dino',\n",
    "                    \"results_bs64_v100\",\n",
    "                    'dino_comics_swin_ss.pth')\n",
    "weights = torch.load(path)\n",
    "mdl = OrderedDict()\n",
    "for k in weights[\"teacher\"]:\n",
    "    #print(k.replace('backbone.','').replace('stages','layers').replace('projection','proj'), \"  -----> \", weights[\"teacher\"][k].shape)\n",
    "    if \"head\" not in k:\n",
    "        print(\"K : \", k, \"Value : \", weights[\"teacher\"][k].shape)\n",
    "        model_backbone_DINO_SWIN_FPN_HEAD_MASKRCNN[k] = weights[\"teacher\"][k]\n",
    "        #cur_name = k.replace('backbone.','').replace('stages','layers').replace('projection','proj').replace('w_msa.','')\n",
    "        #model_backbone_DINO_SWIN_FPN_HEAD_MASKRCNN[cur_name] = weights[\"teacher\"][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K :  neck.lateral_convs.0.conv.weight    V:  torch.Size([256, 96, 1, 1])\n",
      " K :  neck.lateral_convs.0.conv.bias    V:  torch.Size([256])\n",
      " K :  neck.lateral_convs.1.conv.weight    V:  torch.Size([256, 192, 1, 1])\n",
      " K :  neck.lateral_convs.1.conv.bias    V:  torch.Size([256])\n",
      " K :  neck.lateral_convs.2.conv.weight    V:  torch.Size([256, 384, 1, 1])\n",
      " K :  neck.lateral_convs.2.conv.bias    V:  torch.Size([256])\n",
      " K :  neck.lateral_convs.3.conv.weight    V:  torch.Size([256, 768, 1, 1])\n",
      " K :  neck.lateral_convs.3.conv.bias    V:  torch.Size([256])\n",
      " K :  neck.fpn_convs.0.conv.weight    V:  torch.Size([256, 256, 3, 3])\n",
      " K :  neck.fpn_convs.0.conv.bias    V:  torch.Size([256])\n",
      " K :  neck.fpn_convs.1.conv.weight    V:  torch.Size([256, 256, 3, 3])\n",
      " K :  neck.fpn_convs.1.conv.bias    V:  torch.Size([256])\n",
      " K :  neck.fpn_convs.2.conv.weight    V:  torch.Size([256, 256, 3, 3])\n",
      " K :  neck.fpn_convs.2.conv.bias    V:  torch.Size([256])\n",
      " K :  neck.fpn_convs.3.conv.weight    V:  torch.Size([256, 256, 3, 3])\n",
      " K :  neck.fpn_convs.3.conv.bias    V:  torch.Size([256])\n",
      " K :  rpn_head.rpn_conv.weight    V:  torch.Size([256, 256, 3, 3])\n",
      " K :  rpn_head.rpn_conv.bias    V:  torch.Size([256])\n",
      " K :  rpn_head.rpn_cls.weight    V:  torch.Size([3, 256, 1, 1])\n",
      " K :  rpn_head.rpn_cls.bias    V:  torch.Size([3])\n",
      " K :  rpn_head.rpn_reg.weight    V:  torch.Size([12, 256, 1, 1])\n",
      " K :  rpn_head.rpn_reg.bias    V:  torch.Size([12])\n",
      " K :  roi_head.bbox_head.fc_cls.weight    V:  torch.Size([81, 1024])\n",
      " K :  roi_head.bbox_head.fc_cls.bias    V:  torch.Size([81])\n",
      " K :  roi_head.bbox_head.fc_reg.weight    V:  torch.Size([320, 1024])\n",
      " K :  roi_head.bbox_head.fc_reg.bias    V:  torch.Size([320])\n",
      " K :  roi_head.bbox_head.shared_fcs.0.weight    V:  torch.Size([1024, 12544])\n",
      " K :  roi_head.bbox_head.shared_fcs.0.bias    V:  torch.Size([1024])\n",
      " K :  roi_head.bbox_head.shared_fcs.1.weight    V:  torch.Size([1024, 1024])\n",
      " K :  roi_head.bbox_head.shared_fcs.1.bias    V:  torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "maskrcnn_swin_t = torch.load('/scratch/users/ckoksal20/COMICS_Self_Supervised_Learning/Transformer-SSL/mask_rcnn_swin-t-p4-w7_fpn_1x_coco_20210902_120937-9d6b7cfa.pth')\n",
    "maskrcnn_weights = maskrcnn_swin_t[\"state_dict\"]\n",
    "\n",
    "for k,v in maskrcnn_weights.items():\n",
    "    if \"backbone\" not in k and \"mask_head\" not in k:\n",
    "        print(\" K : \",k, \"   V: \",v.shape)\n",
    "        model_backbone_DINO_SWIN_FPN_HEAD_MASKRCNN[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dict()\n",
    "out[\"state_dict\"] = model_backbone_DINO_SWIN_FPN_HEAD_MASKRCNN\n",
    "torch.save(out, \"model_backbone_DINO_SWIN_FPN_HEAD_MASKRCNN.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed.proj.weight -->  torch.Size([96, 3, 4, 4])\n",
      "patch_embed.proj.bias -->  torch.Size([96])\n",
      "patch_embed.norm.weight -->  torch.Size([96])\n",
      "patch_embed.norm.bias -->  torch.Size([96])\n",
      "layers.0.blocks.0.norm1.weight -->  torch.Size([96])\n",
      "layers.0.blocks.0.norm1.bias -->  torch.Size([96])\n",
      "layers.0.blocks.0.attn.relative_position_bias_table -->  torch.Size([169, 3])\n",
      "layers.0.blocks.0.attn.relative_position_index -->  torch.Size([49, 49])\n",
      "layers.0.blocks.0.attn.qkv.weight -->  torch.Size([288, 96])\n",
      "layers.0.blocks.0.attn.qkv.bias -->  torch.Size([288])\n",
      "layers.0.blocks.0.attn.proj.weight -->  torch.Size([96, 96])\n",
      "layers.0.blocks.0.attn.proj.bias -->  torch.Size([96])\n",
      "layers.0.blocks.0.norm2.weight -->  torch.Size([96])\n",
      "layers.0.blocks.0.norm2.bias -->  torch.Size([96])\n",
      "layers.0.blocks.0.ffn.layers.0.0.weight -->  torch.Size([384, 96])\n",
      "layers.0.blocks.0.ffn.layers.0.0.bias -->  torch.Size([384])\n",
      "layers.0.blocks.0.ffn.layers.1.weight -->  torch.Size([96, 384])\n",
      "layers.0.blocks.0.ffn.layers.1.bias -->  torch.Size([96])\n",
      "layers.0.blocks.1.norm1.weight -->  torch.Size([96])\n",
      "layers.0.blocks.1.norm1.bias -->  torch.Size([96])\n",
      "layers.0.blocks.1.attn.relative_position_bias_table -->  torch.Size([169, 3])\n",
      "layers.0.blocks.1.attn.relative_position_index -->  torch.Size([49, 49])\n",
      "layers.0.blocks.1.attn.qkv.weight -->  torch.Size([288, 96])\n",
      "layers.0.blocks.1.attn.qkv.bias -->  torch.Size([288])\n",
      "layers.0.blocks.1.attn.proj.weight -->  torch.Size([96, 96])\n",
      "layers.0.blocks.1.attn.proj.bias -->  torch.Size([96])\n",
      "layers.0.blocks.1.norm2.weight -->  torch.Size([96])\n",
      "layers.0.blocks.1.norm2.bias -->  torch.Size([96])\n",
      "layers.0.blocks.1.ffn.layers.0.0.weight -->  torch.Size([384, 96])\n",
      "layers.0.blocks.1.ffn.layers.0.0.bias -->  torch.Size([384])\n",
      "layers.0.blocks.1.ffn.layers.1.weight -->  torch.Size([96, 384])\n",
      "layers.0.blocks.1.ffn.layers.1.bias -->  torch.Size([96])\n",
      "layers.0.downsample.norm.weight -->  torch.Size([384])\n",
      "layers.0.downsample.norm.bias -->  torch.Size([384])\n",
      "layers.0.downsample.reduction.weight -->  torch.Size([192, 384])\n",
      "layers.1.blocks.0.norm1.weight -->  torch.Size([192])\n",
      "layers.1.blocks.0.norm1.bias -->  torch.Size([192])\n",
      "layers.1.blocks.0.attn.relative_position_bias_table -->  torch.Size([169, 6])\n",
      "layers.1.blocks.0.attn.relative_position_index -->  torch.Size([49, 49])\n",
      "layers.1.blocks.0.attn.qkv.weight -->  torch.Size([576, 192])\n",
      "layers.1.blocks.0.attn.qkv.bias -->  torch.Size([576])\n",
      "layers.1.blocks.0.attn.proj.weight -->  torch.Size([192, 192])\n",
      "layers.1.blocks.0.attn.proj.bias -->  torch.Size([192])\n",
      "layers.1.blocks.0.norm2.weight -->  torch.Size([192])\n",
      "layers.1.blocks.0.norm2.bias -->  torch.Size([192])\n",
      "layers.1.blocks.0.ffn.layers.0.0.weight -->  torch.Size([768, 192])\n",
      "layers.1.blocks.0.ffn.layers.0.0.bias -->  torch.Size([768])\n",
      "layers.1.blocks.0.ffn.layers.1.weight -->  torch.Size([192, 768])\n",
      "layers.1.blocks.0.ffn.layers.1.bias -->  torch.Size([192])\n",
      "layers.1.blocks.1.norm1.weight -->  torch.Size([192])\n",
      "layers.1.blocks.1.norm1.bias -->  torch.Size([192])\n",
      "layers.1.blocks.1.attn.relative_position_bias_table -->  torch.Size([169, 6])\n",
      "layers.1.blocks.1.attn.relative_position_index -->  torch.Size([49, 49])\n",
      "layers.1.blocks.1.attn.qkv.weight -->  torch.Size([576, 192])\n",
      "layers.1.blocks.1.attn.qkv.bias -->  torch.Size([576])\n",
      "layers.1.blocks.1.attn.proj.weight -->  torch.Size([192, 192])\n",
      "layers.1.blocks.1.attn.proj.bias -->  torch.Size([192])\n",
      "layers.1.blocks.1.norm2.weight -->  torch.Size([192])\n",
      "layers.1.blocks.1.norm2.bias -->  torch.Size([192])\n",
      "layers.1.blocks.1.ffn.layers.0.0.weight -->  torch.Size([768, 192])\n",
      "layers.1.blocks.1.ffn.layers.0.0.bias -->  torch.Size([768])\n",
      "layers.1.blocks.1.ffn.layers.1.weight -->  torch.Size([192, 768])\n",
      "layers.1.blocks.1.ffn.layers.1.bias -->  torch.Size([192])\n",
      "layers.1.downsample.norm.weight -->  torch.Size([768])\n",
      "layers.1.downsample.norm.bias -->  torch.Size([768])\n",
      "layers.1.downsample.reduction.weight -->  torch.Size([384, 768])\n",
      "layers.2.blocks.0.norm1.weight -->  torch.Size([384])\n",
      "layers.2.blocks.0.norm1.bias -->  torch.Size([384])\n",
      "layers.2.blocks.0.attn.relative_position_bias_table -->  torch.Size([169, 12])\n",
      "layers.2.blocks.0.attn.relative_position_index -->  torch.Size([49, 49])\n",
      "layers.2.blocks.0.attn.qkv.weight -->  torch.Size([1152, 384])\n",
      "layers.2.blocks.0.attn.qkv.bias -->  torch.Size([1152])\n",
      "layers.2.blocks.0.attn.proj.weight -->  torch.Size([384, 384])\n",
      "layers.2.blocks.0.attn.proj.bias -->  torch.Size([384])\n",
      "layers.2.blocks.0.norm2.weight -->  torch.Size([384])\n",
      "layers.2.blocks.0.norm2.bias -->  torch.Size([384])\n",
      "layers.2.blocks.0.ffn.layers.0.0.weight -->  torch.Size([1536, 384])\n",
      "layers.2.blocks.0.ffn.layers.0.0.bias -->  torch.Size([1536])\n",
      "layers.2.blocks.0.ffn.layers.1.weight -->  torch.Size([384, 1536])\n",
      "layers.2.blocks.0.ffn.layers.1.bias -->  torch.Size([384])\n",
      "layers.2.blocks.1.norm1.weight -->  torch.Size([384])\n",
      "layers.2.blocks.1.norm1.bias -->  torch.Size([384])\n",
      "layers.2.blocks.1.attn.relative_position_bias_table -->  torch.Size([169, 12])\n",
      "layers.2.blocks.1.attn.relative_position_index -->  torch.Size([49, 49])\n",
      "layers.2.blocks.1.attn.qkv.weight -->  torch.Size([1152, 384])\n",
      "layers.2.blocks.1.attn.qkv.bias -->  torch.Size([1152])\n",
      "layers.2.blocks.1.attn.proj.weight -->  torch.Size([384, 384])\n",
      "layers.2.blocks.1.attn.proj.bias -->  torch.Size([384])\n",
      "layers.2.blocks.1.norm2.weight -->  torch.Size([384])\n",
      "layers.2.blocks.1.norm2.bias -->  torch.Size([384])\n",
      "layers.2.blocks.1.ffn.layers.0.0.weight -->  torch.Size([1536, 384])\n",
      "layers.2.blocks.1.ffn.layers.0.0.bias -->  torch.Size([1536])\n",
      "layers.2.blocks.1.ffn.layers.1.weight -->  torch.Size([384, 1536])\n",
      "layers.2.blocks.1.ffn.layers.1.bias -->  torch.Size([384])\n",
      "layers.2.blocks.2.norm1.weight -->  torch.Size([384])\n",
      "layers.2.blocks.2.norm1.bias -->  torch.Size([384])\n",
      "layers.2.blocks.2.attn.relative_position_bias_table -->  torch.Size([169, 12])\n",
      "layers.2.blocks.2.attn.relative_position_index -->  torch.Size([49, 49])\n",
      "layers.2.blocks.2.attn.qkv.weight -->  torch.Size([1152, 384])\n",
      "layers.2.blocks.2.attn.qkv.bias -->  torch.Size([1152])\n",
      "layers.2.blocks.2.attn.proj.weight -->  torch.Size([384, 384])\n",
      "layers.2.blocks.2.attn.proj.bias -->  torch.Size([384])\n",
      "layers.2.blocks.2.norm2.weight -->  torch.Size([384])\n",
      "layers.2.blocks.2.norm2.bias -->  torch.Size([384])\n",
      "layers.2.blocks.2.ffn.layers.0.0.weight -->  torch.Size([1536, 384])\n",
      "layers.2.blocks.2.ffn.layers.0.0.bias -->  torch.Size([1536])\n",
      "layers.2.blocks.2.ffn.layers.1.weight -->  torch.Size([384, 1536])\n",
      "layers.2.blocks.2.ffn.layers.1.bias -->  torch.Size([384])\n",
      "layers.2.blocks.3.norm1.weight -->  torch.Size([384])\n",
      "layers.2.blocks.3.norm1.bias -->  torch.Size([384])\n",
      "layers.2.blocks.3.attn.relative_position_bias_table -->  torch.Size([169, 12])\n",
      "layers.2.blocks.3.attn.relative_position_index -->  torch.Size([49, 49])\n",
      "layers.2.blocks.3.attn.qkv.weight -->  torch.Size([1152, 384])\n",
      "layers.2.blocks.3.attn.qkv.bias -->  torch.Size([1152])\n",
      "layers.2.blocks.3.attn.proj.weight -->  torch.Size([384, 384])\n",
      "layers.2.blocks.3.attn.proj.bias -->  torch.Size([384])\n",
      "layers.2.blocks.3.norm2.weight -->  torch.Size([384])\n",
      "layers.2.blocks.3.norm2.bias -->  torch.Size([384])\n",
      "layers.2.blocks.3.ffn.layers.0.0.weight -->  torch.Size([1536, 384])\n",
      "layers.2.blocks.3.ffn.layers.0.0.bias -->  torch.Size([1536])\n",
      "layers.2.blocks.3.ffn.layers.1.weight -->  torch.Size([384, 1536])\n",
      "layers.2.blocks.3.ffn.layers.1.bias -->  torch.Size([384])\n",
      "layers.2.blocks.4.norm1.weight -->  torch.Size([384])\n",
      "layers.2.blocks.4.norm1.bias -->  torch.Size([384])\n",
      "layers.2.blocks.4.attn.relative_position_bias_table -->  torch.Size([169, 12])\n",
      "layers.2.blocks.4.attn.relative_position_index -->  torch.Size([49, 49])\n",
      "layers.2.blocks.4.attn.qkv.weight -->  torch.Size([1152, 384])\n",
      "layers.2.blocks.4.attn.qkv.bias -->  torch.Size([1152])\n",
      "layers.2.blocks.4.attn.proj.weight -->  torch.Size([384, 384])\n",
      "layers.2.blocks.4.attn.proj.bias -->  torch.Size([384])\n",
      "layers.2.blocks.4.norm2.weight -->  torch.Size([384])\n",
      "layers.2.blocks.4.norm2.bias -->  torch.Size([384])\n",
      "layers.2.blocks.4.ffn.layers.0.0.weight -->  torch.Size([1536, 384])\n",
      "layers.2.blocks.4.ffn.layers.0.0.bias -->  torch.Size([1536])\n",
      "layers.2.blocks.4.ffn.layers.1.weight -->  torch.Size([384, 1536])\n",
      "layers.2.blocks.4.ffn.layers.1.bias -->  torch.Size([384])\n",
      "layers.2.blocks.5.norm1.weight -->  torch.Size([384])\n",
      "layers.2.blocks.5.norm1.bias -->  torch.Size([384])\n",
      "layers.2.blocks.5.attn.relative_position_bias_table -->  torch.Size([169, 12])\n",
      "layers.2.blocks.5.attn.relative_position_index -->  torch.Size([49, 49])\n",
      "layers.2.blocks.5.attn.qkv.weight -->  torch.Size([1152, 384])\n",
      "layers.2.blocks.5.attn.qkv.bias -->  torch.Size([1152])\n",
      "layers.2.blocks.5.attn.proj.weight -->  torch.Size([384, 384])\n",
      "layers.2.blocks.5.attn.proj.bias -->  torch.Size([384])\n",
      "layers.2.blocks.5.norm2.weight -->  torch.Size([384])\n",
      "layers.2.blocks.5.norm2.bias -->  torch.Size([384])\n",
      "layers.2.blocks.5.ffn.layers.0.0.weight -->  torch.Size([1536, 384])\n",
      "layers.2.blocks.5.ffn.layers.0.0.bias -->  torch.Size([1536])\n",
      "layers.2.blocks.5.ffn.layers.1.weight -->  torch.Size([384, 1536])\n",
      "layers.2.blocks.5.ffn.layers.1.bias -->  torch.Size([384])\n",
      "layers.2.downsample.norm.weight -->  torch.Size([1536])\n",
      "layers.2.downsample.norm.bias -->  torch.Size([1536])\n",
      "layers.2.downsample.reduction.weight -->  torch.Size([768, 1536])\n",
      "layers.3.blocks.0.norm1.weight -->  torch.Size([768])\n",
      "layers.3.blocks.0.norm1.bias -->  torch.Size([768])\n",
      "layers.3.blocks.0.attn.relative_position_bias_table -->  torch.Size([169, 24])\n",
      "layers.3.blocks.0.attn.relative_position_index -->  torch.Size([49, 49])\n",
      "layers.3.blocks.0.attn.qkv.weight -->  torch.Size([2304, 768])\n",
      "layers.3.blocks.0.attn.qkv.bias -->  torch.Size([2304])\n",
      "layers.3.blocks.0.attn.proj.weight -->  torch.Size([768, 768])\n",
      "layers.3.blocks.0.attn.proj.bias -->  torch.Size([768])\n",
      "layers.3.blocks.0.norm2.weight -->  torch.Size([768])\n",
      "layers.3.blocks.0.norm2.bias -->  torch.Size([768])\n",
      "layers.3.blocks.0.ffn.layers.0.0.weight -->  torch.Size([3072, 768])\n",
      "layers.3.blocks.0.ffn.layers.0.0.bias -->  torch.Size([3072])\n",
      "layers.3.blocks.0.ffn.layers.1.weight -->  torch.Size([768, 3072])\n",
      "layers.3.blocks.0.ffn.layers.1.bias -->  torch.Size([768])\n",
      "layers.3.blocks.1.norm1.weight -->  torch.Size([768])\n",
      "layers.3.blocks.1.norm1.bias -->  torch.Size([768])\n",
      "layers.3.blocks.1.attn.relative_position_bias_table -->  torch.Size([169, 24])\n",
      "layers.3.blocks.1.attn.relative_position_index -->  torch.Size([49, 49])\n",
      "layers.3.blocks.1.attn.qkv.weight -->  torch.Size([2304, 768])\n",
      "layers.3.blocks.1.attn.qkv.bias -->  torch.Size([2304])\n",
      "layers.3.blocks.1.attn.proj.weight -->  torch.Size([768, 768])\n",
      "layers.3.blocks.1.attn.proj.bias -->  torch.Size([768])\n",
      "layers.3.blocks.1.norm2.weight -->  torch.Size([768])\n",
      "layers.3.blocks.1.norm2.bias -->  torch.Size([768])\n",
      "layers.3.blocks.1.ffn.layers.0.0.weight -->  torch.Size([3072, 768])\n",
      "layers.3.blocks.1.ffn.layers.0.0.bias -->  torch.Size([3072])\n",
      "layers.3.blocks.1.ffn.layers.1.weight -->  torch.Size([768, 3072])\n",
      "layers.3.blocks.1.ffn.layers.1.bias -->  torch.Size([768])\n",
      "norm0.weight -->  torch.Size([96])\n",
      "norm0.bias -->  torch.Size([96])\n",
      "norm1.weight -->  torch.Size([192])\n",
      "norm1.bias -->  torch.Size([192])\n",
      "norm2.weight -->  torch.Size([384])\n",
      "norm2.bias -->  torch.Size([384])\n",
      "norm3.weight -->  torch.Size([768])\n",
      "norm3.bias -->  torch.Size([768])\n",
      "ln.weight -->  torch.Size([768])\n",
      "ln.bias -->  torch.Size([768])\n",
      "neck.lateral_convs.0.conv.weight -->  torch.Size([256, 96, 1, 1])\n",
      "neck.lateral_convs.0.conv.bias -->  torch.Size([256])\n",
      "neck.lateral_convs.1.conv.weight -->  torch.Size([256, 192, 1, 1])\n",
      "neck.lateral_convs.1.conv.bias -->  torch.Size([256])\n",
      "neck.lateral_convs.2.conv.weight -->  torch.Size([256, 384, 1, 1])\n",
      "neck.lateral_convs.2.conv.bias -->  torch.Size([256])\n",
      "neck.lateral_convs.3.conv.weight -->  torch.Size([256, 768, 1, 1])\n",
      "neck.lateral_convs.3.conv.bias -->  torch.Size([256])\n",
      "neck.fpn_convs.0.conv.weight -->  torch.Size([256, 256, 3, 3])\n",
      "neck.fpn_convs.0.conv.bias -->  torch.Size([256])\n",
      "neck.fpn_convs.1.conv.weight -->  torch.Size([256, 256, 3, 3])\n",
      "neck.fpn_convs.1.conv.bias -->  torch.Size([256])\n",
      "neck.fpn_convs.2.conv.weight -->  torch.Size([256, 256, 3, 3])\n",
      "neck.fpn_convs.2.conv.bias -->  torch.Size([256])\n",
      "neck.fpn_convs.3.conv.weight -->  torch.Size([256, 256, 3, 3])\n",
      "neck.fpn_convs.3.conv.bias -->  torch.Size([256])\n",
      "rpn_head.rpn_conv.weight -->  torch.Size([256, 256, 3, 3])\n",
      "rpn_head.rpn_conv.bias -->  torch.Size([256])\n",
      "rpn_head.rpn_cls.weight -->  torch.Size([3, 256, 1, 1])\n",
      "rpn_head.rpn_cls.bias -->  torch.Size([3])\n",
      "rpn_head.rpn_reg.weight -->  torch.Size([12, 256, 1, 1])\n",
      "rpn_head.rpn_reg.bias -->  torch.Size([12])\n",
      "roi_head.bbox_head.fc_cls.weight -->  torch.Size([81, 1024])\n",
      "roi_head.bbox_head.fc_cls.bias -->  torch.Size([81])\n",
      "roi_head.bbox_head.fc_reg.weight -->  torch.Size([320, 1024])\n",
      "roi_head.bbox_head.fc_reg.bias -->  torch.Size([320])\n",
      "roi_head.bbox_head.shared_fcs.0.weight -->  torch.Size([1024, 12544])\n",
      "roi_head.bbox_head.shared_fcs.0.bias -->  torch.Size([1024])\n",
      "roi_head.bbox_head.shared_fcs.1.weight -->  torch.Size([1024, 1024])\n",
      "roi_head.bbox_head.shared_fcs.1.bias -->  torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "for k,v in out[\"model\"].items():\n",
    "    print(k, \"--> \",v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-11 07:53:09--  https://download.openmmlab.com/mmdetection/v2.0/swin/mask_rcnn_swin-t-p4-w7_fpn_1x_coco/mask_rcnn_swin-t-p4-w7_fpn_1x_coco_20210902_120937-9d6b7cfa.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.254.186.225\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.254.186.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 191461353 (183M) [application/octet-stream]\n",
      "Saving to: mask_rcnn_swin-t-p4-w7_fpn_1x_coco_20210902_120937-9d6b7cfa.pth\n",
      "\n",
      "100%[======================================>] 191.461.353 12,2MB/s   in 14s    \n",
      "\n",
      "2021-10-11 07:53:28 (12,6 MB/s) - mask_rcnn_swin-t-p4-w7_fpn_1x_coco_20210902_120937-9d6b7cfa.pth saved [191461353/191461353]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## MM DETECTION SWIN TINY MODEL\n",
    "!wget https://download.openmmlab.com/mmdetection/v2.0/swin/mask_rcnn_swin-t-p4-w7_fpn_1x_coco/mask_rcnn_swin-t-p4-w7_fpn_1x_coco_20210902_120937-9d6b7cfa.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "swintiny_model_maskrcnn = torch.load(\"mask_rcnn_swin-t-p4-w7_fpn_1x_coco_20210902_120937-9d6b7cfa.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key :  backbone.patch_embed.projection.weight  v torch.Size([96, 3, 4, 4])\n",
      "Key :  backbone.patch_embed.projection.bias  v torch.Size([96])\n",
      "Key :  backbone.patch_embed.norm.weight  v torch.Size([96])\n",
      "Key :  backbone.patch_embed.norm.bias  v torch.Size([96])\n",
      "Key :  backbone.stages.0.blocks.0.norm1.weight  v torch.Size([96])\n",
      "Key :  backbone.stages.0.blocks.0.norm1.bias  v torch.Size([96])\n",
      "Key :  backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table  v torch.Size([169, 3])\n",
      "Key :  backbone.stages.0.blocks.0.attn.w_msa.relative_position_index  v torch.Size([49, 49])\n",
      "Key :  backbone.stages.0.blocks.0.attn.w_msa.qkv.weight  v torch.Size([288, 96])\n",
      "Key :  backbone.stages.0.blocks.0.attn.w_msa.qkv.bias  v torch.Size([288])\n",
      "Key :  backbone.stages.0.blocks.0.attn.w_msa.proj.weight  v torch.Size([96, 96])\n",
      "Key :  backbone.stages.0.blocks.0.attn.w_msa.proj.bias  v torch.Size([96])\n",
      "Key :  backbone.stages.0.blocks.0.norm2.weight  v torch.Size([96])\n",
      "Key :  backbone.stages.0.blocks.0.norm2.bias  v torch.Size([96])\n",
      "Key :  backbone.stages.0.blocks.0.ffn.layers.0.0.weight  v torch.Size([384, 96])\n",
      "Key :  backbone.stages.0.blocks.0.ffn.layers.0.0.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.0.blocks.0.ffn.layers.1.weight  v torch.Size([96, 384])\n",
      "Key :  backbone.stages.0.blocks.0.ffn.layers.1.bias  v torch.Size([96])\n",
      "Key :  backbone.stages.0.blocks.1.norm1.weight  v torch.Size([96])\n",
      "Key :  backbone.stages.0.blocks.1.norm1.bias  v torch.Size([96])\n",
      "Key :  backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table  v torch.Size([169, 3])\n",
      "Key :  backbone.stages.0.blocks.1.attn.w_msa.relative_position_index  v torch.Size([49, 49])\n",
      "Key :  backbone.stages.0.blocks.1.attn.w_msa.qkv.weight  v torch.Size([288, 96])\n",
      "Key :  backbone.stages.0.blocks.1.attn.w_msa.qkv.bias  v torch.Size([288])\n",
      "Key :  backbone.stages.0.blocks.1.attn.w_msa.proj.weight  v torch.Size([96, 96])\n",
      "Key :  backbone.stages.0.blocks.1.attn.w_msa.proj.bias  v torch.Size([96])\n",
      "Key :  backbone.stages.0.blocks.1.norm2.weight  v torch.Size([96])\n",
      "Key :  backbone.stages.0.blocks.1.norm2.bias  v torch.Size([96])\n",
      "Key :  backbone.stages.0.blocks.1.ffn.layers.0.0.weight  v torch.Size([384, 96])\n",
      "Key :  backbone.stages.0.blocks.1.ffn.layers.0.0.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.0.blocks.1.ffn.layers.1.weight  v torch.Size([96, 384])\n",
      "Key :  backbone.stages.0.blocks.1.ffn.layers.1.bias  v torch.Size([96])\n",
      "Key :  backbone.stages.0.downsample.norm.weight  v torch.Size([384])\n",
      "Key :  backbone.stages.0.downsample.norm.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.0.downsample.reduction.weight  v torch.Size([192, 384])\n",
      "Key :  backbone.stages.1.blocks.0.norm1.weight  v torch.Size([192])\n",
      "Key :  backbone.stages.1.blocks.0.norm1.bias  v torch.Size([192])\n",
      "Key :  backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table  v torch.Size([169, 6])\n",
      "Key :  backbone.stages.1.blocks.0.attn.w_msa.relative_position_index  v torch.Size([49, 49])\n",
      "Key :  backbone.stages.1.blocks.0.attn.w_msa.qkv.weight  v torch.Size([576, 192])\n",
      "Key :  backbone.stages.1.blocks.0.attn.w_msa.qkv.bias  v torch.Size([576])\n",
      "Key :  backbone.stages.1.blocks.0.attn.w_msa.proj.weight  v torch.Size([192, 192])\n",
      "Key :  backbone.stages.1.blocks.0.attn.w_msa.proj.bias  v torch.Size([192])\n",
      "Key :  backbone.stages.1.blocks.0.norm2.weight  v torch.Size([192])\n",
      "Key :  backbone.stages.1.blocks.0.norm2.bias  v torch.Size([192])\n",
      "Key :  backbone.stages.1.blocks.0.ffn.layers.0.0.weight  v torch.Size([768, 192])\n",
      "Key :  backbone.stages.1.blocks.0.ffn.layers.0.0.bias  v torch.Size([768])\n",
      "Key :  backbone.stages.1.blocks.0.ffn.layers.1.weight  v torch.Size([192, 768])\n",
      "Key :  backbone.stages.1.blocks.0.ffn.layers.1.bias  v torch.Size([192])\n",
      "Key :  backbone.stages.1.blocks.1.norm1.weight  v torch.Size([192])\n",
      "Key :  backbone.stages.1.blocks.1.norm1.bias  v torch.Size([192])\n",
      "Key :  backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table  v torch.Size([169, 6])\n",
      "Key :  backbone.stages.1.blocks.1.attn.w_msa.relative_position_index  v torch.Size([49, 49])\n",
      "Key :  backbone.stages.1.blocks.1.attn.w_msa.qkv.weight  v torch.Size([576, 192])\n",
      "Key :  backbone.stages.1.blocks.1.attn.w_msa.qkv.bias  v torch.Size([576])\n",
      "Key :  backbone.stages.1.blocks.1.attn.w_msa.proj.weight  v torch.Size([192, 192])\n",
      "Key :  backbone.stages.1.blocks.1.attn.w_msa.proj.bias  v torch.Size([192])\n",
      "Key :  backbone.stages.1.blocks.1.norm2.weight  v torch.Size([192])\n",
      "Key :  backbone.stages.1.blocks.1.norm2.bias  v torch.Size([192])\n",
      "Key :  backbone.stages.1.blocks.1.ffn.layers.0.0.weight  v torch.Size([768, 192])\n",
      "Key :  backbone.stages.1.blocks.1.ffn.layers.0.0.bias  v torch.Size([768])\n",
      "Key :  backbone.stages.1.blocks.1.ffn.layers.1.weight  v torch.Size([192, 768])\n",
      "Key :  backbone.stages.1.blocks.1.ffn.layers.1.bias  v torch.Size([192])\n",
      "Key :  backbone.stages.1.downsample.norm.weight  v torch.Size([768])\n",
      "Key :  backbone.stages.1.downsample.norm.bias  v torch.Size([768])\n",
      "Key :  backbone.stages.1.downsample.reduction.weight  v torch.Size([384, 768])\n",
      "Key :  backbone.stages.2.blocks.0.norm1.weight  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.0.norm1.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table  v torch.Size([169, 12])\n",
      "Key :  backbone.stages.2.blocks.0.attn.w_msa.relative_position_index  v torch.Size([49, 49])\n",
      "Key :  backbone.stages.2.blocks.0.attn.w_msa.qkv.weight  v torch.Size([1152, 384])\n",
      "Key :  backbone.stages.2.blocks.0.attn.w_msa.qkv.bias  v torch.Size([1152])\n",
      "Key :  backbone.stages.2.blocks.0.attn.w_msa.proj.weight  v torch.Size([384, 384])\n",
      "Key :  backbone.stages.2.blocks.0.attn.w_msa.proj.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.0.norm2.weight  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.0.norm2.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.0.ffn.layers.0.0.weight  v torch.Size([1536, 384])\n",
      "Key :  backbone.stages.2.blocks.0.ffn.layers.0.0.bias  v torch.Size([1536])\n",
      "Key :  backbone.stages.2.blocks.0.ffn.layers.1.weight  v torch.Size([384, 1536])\n",
      "Key :  backbone.stages.2.blocks.0.ffn.layers.1.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.1.norm1.weight  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.1.norm1.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table  v torch.Size([169, 12])\n",
      "Key :  backbone.stages.2.blocks.1.attn.w_msa.relative_position_index  v torch.Size([49, 49])\n",
      "Key :  backbone.stages.2.blocks.1.attn.w_msa.qkv.weight  v torch.Size([1152, 384])\n",
      "Key :  backbone.stages.2.blocks.1.attn.w_msa.qkv.bias  v torch.Size([1152])\n",
      "Key :  backbone.stages.2.blocks.1.attn.w_msa.proj.weight  v torch.Size([384, 384])\n",
      "Key :  backbone.stages.2.blocks.1.attn.w_msa.proj.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.1.norm2.weight  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.1.norm2.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.1.ffn.layers.0.0.weight  v torch.Size([1536, 384])\n",
      "Key :  backbone.stages.2.blocks.1.ffn.layers.0.0.bias  v torch.Size([1536])\n",
      "Key :  backbone.stages.2.blocks.1.ffn.layers.1.weight  v torch.Size([384, 1536])\n",
      "Key :  backbone.stages.2.blocks.1.ffn.layers.1.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.2.norm1.weight  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.2.norm1.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table  v torch.Size([169, 12])\n",
      "Key :  backbone.stages.2.blocks.2.attn.w_msa.relative_position_index  v torch.Size([49, 49])\n",
      "Key :  backbone.stages.2.blocks.2.attn.w_msa.qkv.weight  v torch.Size([1152, 384])\n",
      "Key :  backbone.stages.2.blocks.2.attn.w_msa.qkv.bias  v torch.Size([1152])\n",
      "Key :  backbone.stages.2.blocks.2.attn.w_msa.proj.weight  v torch.Size([384, 384])\n",
      "Key :  backbone.stages.2.blocks.2.attn.w_msa.proj.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.2.norm2.weight  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.2.norm2.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.2.ffn.layers.0.0.weight  v torch.Size([1536, 384])\n",
      "Key :  backbone.stages.2.blocks.2.ffn.layers.0.0.bias  v torch.Size([1536])\n",
      "Key :  backbone.stages.2.blocks.2.ffn.layers.1.weight  v torch.Size([384, 1536])\n",
      "Key :  backbone.stages.2.blocks.2.ffn.layers.1.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.3.norm1.weight  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.3.norm1.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table  v torch.Size([169, 12])\n",
      "Key :  backbone.stages.2.blocks.3.attn.w_msa.relative_position_index  v torch.Size([49, 49])\n",
      "Key :  backbone.stages.2.blocks.3.attn.w_msa.qkv.weight  v torch.Size([1152, 384])\n",
      "Key :  backbone.stages.2.blocks.3.attn.w_msa.qkv.bias  v torch.Size([1152])\n",
      "Key :  backbone.stages.2.blocks.3.attn.w_msa.proj.weight  v torch.Size([384, 384])\n",
      "Key :  backbone.stages.2.blocks.3.attn.w_msa.proj.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.3.norm2.weight  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.3.norm2.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.3.ffn.layers.0.0.weight  v torch.Size([1536, 384])\n",
      "Key :  backbone.stages.2.blocks.3.ffn.layers.0.0.bias  v torch.Size([1536])\n",
      "Key :  backbone.stages.2.blocks.3.ffn.layers.1.weight  v torch.Size([384, 1536])\n",
      "Key :  backbone.stages.2.blocks.3.ffn.layers.1.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.4.norm1.weight  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.4.norm1.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table  v torch.Size([169, 12])\n",
      "Key :  backbone.stages.2.blocks.4.attn.w_msa.relative_position_index  v torch.Size([49, 49])\n",
      "Key :  backbone.stages.2.blocks.4.attn.w_msa.qkv.weight  v torch.Size([1152, 384])\n",
      "Key :  backbone.stages.2.blocks.4.attn.w_msa.qkv.bias  v torch.Size([1152])\n",
      "Key :  backbone.stages.2.blocks.4.attn.w_msa.proj.weight  v torch.Size([384, 384])\n",
      "Key :  backbone.stages.2.blocks.4.attn.w_msa.proj.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.4.norm2.weight  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.4.norm2.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.4.ffn.layers.0.0.weight  v torch.Size([1536, 384])\n",
      "Key :  backbone.stages.2.blocks.4.ffn.layers.0.0.bias  v torch.Size([1536])\n",
      "Key :  backbone.stages.2.blocks.4.ffn.layers.1.weight  v torch.Size([384, 1536])\n",
      "Key :  backbone.stages.2.blocks.4.ffn.layers.1.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.5.norm1.weight  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.5.norm1.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table  v torch.Size([169, 12])\n",
      "Key :  backbone.stages.2.blocks.5.attn.w_msa.relative_position_index  v torch.Size([49, 49])\n",
      "Key :  backbone.stages.2.blocks.5.attn.w_msa.qkv.weight  v torch.Size([1152, 384])\n",
      "Key :  backbone.stages.2.blocks.5.attn.w_msa.qkv.bias  v torch.Size([1152])\n",
      "Key :  backbone.stages.2.blocks.5.attn.w_msa.proj.weight  v torch.Size([384, 384])\n",
      "Key :  backbone.stages.2.blocks.5.attn.w_msa.proj.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.5.norm2.weight  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.5.norm2.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.blocks.5.ffn.layers.0.0.weight  v torch.Size([1536, 384])\n",
      "Key :  backbone.stages.2.blocks.5.ffn.layers.0.0.bias  v torch.Size([1536])\n",
      "Key :  backbone.stages.2.blocks.5.ffn.layers.1.weight  v torch.Size([384, 1536])\n",
      "Key :  backbone.stages.2.blocks.5.ffn.layers.1.bias  v torch.Size([384])\n",
      "Key :  backbone.stages.2.downsample.norm.weight  v torch.Size([1536])\n",
      "Key :  backbone.stages.2.downsample.norm.bias  v torch.Size([1536])\n",
      "Key :  backbone.stages.2.downsample.reduction.weight  v torch.Size([768, 1536])\n",
      "Key :  backbone.stages.3.blocks.0.norm1.weight  v torch.Size([768])\n",
      "Key :  backbone.stages.3.blocks.0.norm1.bias  v torch.Size([768])\n",
      "Key :  backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table  v torch.Size([169, 24])\n",
      "Key :  backbone.stages.3.blocks.0.attn.w_msa.relative_position_index  v torch.Size([49, 49])\n",
      "Key :  backbone.stages.3.blocks.0.attn.w_msa.qkv.weight  v torch.Size([2304, 768])\n",
      "Key :  backbone.stages.3.blocks.0.attn.w_msa.qkv.bias  v torch.Size([2304])\n",
      "Key :  backbone.stages.3.blocks.0.attn.w_msa.proj.weight  v torch.Size([768, 768])\n",
      "Key :  backbone.stages.3.blocks.0.attn.w_msa.proj.bias  v torch.Size([768])\n",
      "Key :  backbone.stages.3.blocks.0.norm2.weight  v torch.Size([768])\n",
      "Key :  backbone.stages.3.blocks.0.norm2.bias  v torch.Size([768])\n",
      "Key :  backbone.stages.3.blocks.0.ffn.layers.0.0.weight  v torch.Size([3072, 768])\n",
      "Key :  backbone.stages.3.blocks.0.ffn.layers.0.0.bias  v torch.Size([3072])\n",
      "Key :  backbone.stages.3.blocks.0.ffn.layers.1.weight  v torch.Size([768, 3072])\n",
      "Key :  backbone.stages.3.blocks.0.ffn.layers.1.bias  v torch.Size([768])\n",
      "Key :  backbone.stages.3.blocks.1.norm1.weight  v torch.Size([768])\n",
      "Key :  backbone.stages.3.blocks.1.norm1.bias  v torch.Size([768])\n",
      "Key :  backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table  v torch.Size([169, 24])\n",
      "Key :  backbone.stages.3.blocks.1.attn.w_msa.relative_position_index  v torch.Size([49, 49])\n",
      "Key :  backbone.stages.3.blocks.1.attn.w_msa.qkv.weight  v torch.Size([2304, 768])\n",
      "Key :  backbone.stages.3.blocks.1.attn.w_msa.qkv.bias  v torch.Size([2304])\n",
      "Key :  backbone.stages.3.blocks.1.attn.w_msa.proj.weight  v torch.Size([768, 768])\n",
      "Key :  backbone.stages.3.blocks.1.attn.w_msa.proj.bias  v torch.Size([768])\n",
      "Key :  backbone.stages.3.blocks.1.norm2.weight  v torch.Size([768])\n",
      "Key :  backbone.stages.3.blocks.1.norm2.bias  v torch.Size([768])\n",
      "Key :  backbone.stages.3.blocks.1.ffn.layers.0.0.weight  v torch.Size([3072, 768])\n",
      "Key :  backbone.stages.3.blocks.1.ffn.layers.0.0.bias  v torch.Size([3072])\n",
      "Key :  backbone.stages.3.blocks.1.ffn.layers.1.weight  v torch.Size([768, 3072])\n",
      "Key :  backbone.stages.3.blocks.1.ffn.layers.1.bias  v torch.Size([768])\n",
      "Key :  backbone.norm0.weight  v torch.Size([96])\n",
      "Key :  backbone.norm0.bias  v torch.Size([96])\n",
      "Key :  backbone.norm1.weight  v torch.Size([192])\n",
      "Key :  backbone.norm1.bias  v torch.Size([192])\n",
      "Key :  backbone.norm2.weight  v torch.Size([384])\n",
      "Key :  backbone.norm2.bias  v torch.Size([384])\n",
      "Key :  backbone.norm3.weight  v torch.Size([768])\n",
      "Key :  backbone.norm3.bias  v torch.Size([768])\n",
      "Key :  neck.lateral_convs.0.conv.weight  v torch.Size([256, 96, 1, 1])\n",
      "Key :  neck.lateral_convs.0.conv.bias  v torch.Size([256])\n",
      "Key :  neck.lateral_convs.1.conv.weight  v torch.Size([256, 192, 1, 1])\n",
      "Key :  neck.lateral_convs.1.conv.bias  v torch.Size([256])\n",
      "Key :  neck.lateral_convs.2.conv.weight  v torch.Size([256, 384, 1, 1])\n",
      "Key :  neck.lateral_convs.2.conv.bias  v torch.Size([256])\n",
      "Key :  neck.lateral_convs.3.conv.weight  v torch.Size([256, 768, 1, 1])\n",
      "Key :  neck.lateral_convs.3.conv.bias  v torch.Size([256])\n",
      "Key :  neck.fpn_convs.0.conv.weight  v torch.Size([256, 256, 3, 3])\n",
      "Key :  neck.fpn_convs.0.conv.bias  v torch.Size([256])\n",
      "Key :  neck.fpn_convs.1.conv.weight  v torch.Size([256, 256, 3, 3])\n",
      "Key :  neck.fpn_convs.1.conv.bias  v torch.Size([256])\n",
      "Key :  neck.fpn_convs.2.conv.weight  v torch.Size([256, 256, 3, 3])\n",
      "Key :  neck.fpn_convs.2.conv.bias  v torch.Size([256])\n",
      "Key :  neck.fpn_convs.3.conv.weight  v torch.Size([256, 256, 3, 3])\n",
      "Key :  neck.fpn_convs.3.conv.bias  v torch.Size([256])\n",
      "Key :  rpn_head.rpn_conv.weight  v torch.Size([256, 256, 3, 3])\n",
      "Key :  rpn_head.rpn_conv.bias  v torch.Size([256])\n",
      "Key :  rpn_head.rpn_cls.weight  v torch.Size([3, 256, 1, 1])\n",
      "Key :  rpn_head.rpn_cls.bias  v torch.Size([3])\n",
      "Key :  rpn_head.rpn_reg.weight  v torch.Size([12, 256, 1, 1])\n",
      "Key :  rpn_head.rpn_reg.bias  v torch.Size([12])\n",
      "Key :  roi_head.bbox_head.fc_cls.weight  v torch.Size([81, 1024])\n",
      "Key :  roi_head.bbox_head.fc_cls.bias  v torch.Size([81])\n",
      "Key :  roi_head.bbox_head.fc_reg.weight  v torch.Size([320, 1024])\n",
      "Key :  roi_head.bbox_head.fc_reg.bias  v torch.Size([320])\n",
      "Key :  roi_head.bbox_head.shared_fcs.0.weight  v torch.Size([1024, 12544])\n",
      "Key :  roi_head.bbox_head.shared_fcs.0.bias  v torch.Size([1024])\n",
      "Key :  roi_head.bbox_head.shared_fcs.1.weight  v torch.Size([1024, 1024])\n",
      "Key :  roi_head.bbox_head.shared_fcs.1.bias  v torch.Size([1024])\n",
      "Key :  roi_head.mask_head.convs.0.conv.weight  v torch.Size([256, 256, 3, 3])\n",
      "Key :  roi_head.mask_head.convs.0.conv.bias  v torch.Size([256])\n",
      "Key :  roi_head.mask_head.convs.1.conv.weight  v torch.Size([256, 256, 3, 3])\n",
      "Key :  roi_head.mask_head.convs.1.conv.bias  v torch.Size([256])\n",
      "Key :  roi_head.mask_head.convs.2.conv.weight  v torch.Size([256, 256, 3, 3])\n",
      "Key :  roi_head.mask_head.convs.2.conv.bias  v torch.Size([256])\n",
      "Key :  roi_head.mask_head.convs.3.conv.weight  v torch.Size([256, 256, 3, 3])\n",
      "Key :  roi_head.mask_head.convs.3.conv.bias  v torch.Size([256])\n",
      "Key :  roi_head.mask_head.upsample.weight  v torch.Size([256, 256, 2, 2])\n",
      "Key :  roi_head.mask_head.upsample.bias  v torch.Size([256])\n",
      "Key :  roi_head.mask_head.conv_logits.weight  v torch.Size([80, 256, 1, 1])\n",
      "Key :  roi_head.mask_head.conv_logits.bias  v torch.Size([80])\n"
     ]
    }
   ],
   "source": [
    "for key, val in swintiny_model_maskrcnn[\"state_dict\"].items():\n",
    "    print(\"Key : \",key, \" v\", val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "openmmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
